{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jHXp1p7QOiv-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import  SimpleImputer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrrCE4mL9wSn"
      },
      "source": [
        "##Ejercicio 1: Predicción de streams de canciones de Spotify. | Regresión\n",
        "##Lineal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPRez1PS-E3F"
      },
      "source": [
        "#Predecir el número total de streams acumulados en Spotify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "310goyXcF7Re",
        "outputId": "746222c4-2f97-4d08-d316-0d2963a89a7b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './sample_data/spotify-2023.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5fa5f94b0e67>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# The 'latin-1' encoding (also known as 'iso-8859-1') is a common encoding for European languages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# If this doesn't work, try other encodings like 'utf-16', 'cp1252', etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Display the first few rows of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './sample_data/spotify-2023.csv'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Local path to the downloaded CSV file\n",
        "csv_file_path = \"./sample_data/spotify-2023.csv\"\n",
        "\n",
        "# Read the CSV file using the correct path, specifying the encoding\n",
        "# The 'latin-1' encoding (also known as 'iso-8859-1') is a common encoding for European languages.\n",
        "# If this doesn't work, try other encodings like 'utf-16', 'cp1252', etc.\n",
        "data = pd.read_csv(csv_file_path, encoding='latin-1')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nscXfhpV0tSn"
      },
      "source": [
        "##Info general"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNGidMNa1BYK"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGtNiahI1epS"
      },
      "source": [
        "##Descripción estadpistica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt2Hij5E1m_p"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xsd89ut2cvR"
      },
      "source": [
        "##Descripción de categoricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WOUGYvL2qsu"
      },
      "outputs": [],
      "source": [
        "data.describe(include= ['O']) #object data type only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wajqRY4U4Cbh"
      },
      "outputs": [],
      "source": [
        "data.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE59ipCu4HWA"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "176_Axh14Sgz"
      },
      "outputs": [],
      "source": [
        "data['artist_count']= data['artist_count'].astype(str) #change col datatype()\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leRZ6BYq7D7D"
      },
      "outputs": [],
      "source": [
        "data['track_name'] = data['track_name'].astype(str)\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd2MfPKM7vvo"
      },
      "source": [
        "##Comprobación otliers, outstanding data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJAB6weVL8tw"
      },
      "source": [
        "##Coeficiente de Pearson; mide la fuerza y dirección de una relación lineal.\n",
        "##correlación 1 a -1; eliminar siempre una de las variables correlacionadas vuelve menos redundante; evita overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkUL1eFdOwss"
      },
      "outputs": [],
      "source": [
        "data.var()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSbVPLwPZZra"
      },
      "source": [
        "#features no se encuentran en la misma escala,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APGltPzhUKOg"
      },
      "outputs": [],
      "source": [
        "#Filtrando columnas numéricas:\n",
        "numerical_data = data.select_dtypes(include=[\"float64\", \"int64\"])\n",
        "\n",
        "#calculando varianza; cols numéricas:\n",
        "variance = numerical_data.var()\n",
        "variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lriL0buLVFRq"
      },
      "source": [
        "#Datos categóricos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeQRzKLHaE_s"
      },
      "outputs": [],
      "source": [
        "cat_cols=data.select_dtypes(include='O').columns # .select_dtypes(include='O') -> seleccionamos columnas categóricas\n",
        "\n",
        "for c in cat_cols:\n",
        "  print('\\nColumna :',c)\n",
        "  print(data[c].value_counts()) # .value_counts() -> Número de observaciones por cada categoría."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dLenU_9bVKl"
      },
      "source": [
        "##Matriz correlación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uuf8p_PbZRF"
      },
      "outputs": [],
      "source": [
        "num_cols=data.select_dtypes(include='number').columns # Manera sencilla de escoger columnas numéricas :D\n",
        "\n",
        "plt.figure(figsize=(14, 10))\n",
        "matriz=data[num_cols].corr() # Este .corr() nos calcula el coeficiente de PEARSON de todas las variables.\n",
        "\n",
        "sns.heatmap(matriz,annot=True) # el annot=true es pa que nos muestre las anotaciones (Osease los valores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZxhLpfffnfU"
      },
      "source": [
        "#Exploración Visual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw6HrvRHf0GJ"
      },
      "outputs": [],
      "source": [
        "#Columnas numéricas\n",
        "for col in num_cols:\n",
        "  print('\\nVisualizaciones para la columna: ',col)\n",
        "  sns.histplot(data[col],kde=True) # Mostrando la distribución de los datos\n",
        "  plt.show()\n",
        "  sns.boxplot(data[col]) # para ver si hay outliers, individual that is markedely different from the rest of data.\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpN8Iqa9jdQI"
      },
      "source": [
        "##COLS categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij9Dd3y_juj0"
      },
      "outputs": [],
      "source": [
        "for c in cat_cols:\n",
        "  sns.barplot(data[c])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsFAwu_dxoDv"
      },
      "outputs": [],
      "source": [
        "data.released_year.value_counts()#how many times each unique year appears; creating a new series:\n",
        "                                                                             #another panda data structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8-OVGpIyQKS"
      },
      "outputs": [],
      "source": [
        "data.released_year.value_counts() / len(data) #mean; correlation; mean to zero; normalization;generic scale: 1 to -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHMORe_jysha"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "sns.barplot(data['released_year'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m9-dRWi0GR-"
      },
      "source": [
        "##Podemos apreciar desbalanceo en 2022 y 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BhpUv-R0TZM"
      },
      "outputs": [],
      "source": [
        "##corrigiendo desbalanceo:\n",
        "sns.pairplot(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZtY8X650_CY"
      },
      "source": [
        "#Análisis de datos(notas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C-dT4vwYJSC"
      },
      "source": [
        "##Standar deviation: Transforms data so that it´s mean is 0; and standard deviation of 1\n",
        "##Use it when data follows a Gaussian distribution.\n",
        "##Normalization(Min mAX SCALING):\n",
        "##features in at specific range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_-Wvylk1Eah"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWRIffSi67YD"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"Edad\": [25, 30, 35, 40, 45, 78],\n",
        "    \"Ingreso mensual (miles)\": [35, 50, 70, 90, 120, 600]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxSYnbTT7Y64"
      },
      "outputs": [],
      "source": [
        "# Calcular el promedio de la columna \"Edades\"\n",
        "promedio_edades = df['Edad'].mean() #Selecting edad key and applying\n",
        "                                    #The mean() method.\n",
        "\n",
        "max_edades = df[\"Edad\"].max()\n",
        "print(\"Promedio de Edades:\", promedio_edades)\n",
        "max_edades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FROVmjtC8IV8"
      },
      "outputs": [],
      "source": [
        "# Graficar los datos antes de la estandarización\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "# Corrected column name: 'Ingreso mensual (miles)'\n",
        "            #y f(x)      x\n",
        "plt.scatter(df['Edad'] , df['Ingreso mensual (miles)'])\n",
        "plt.title('Datos sin estandarizar')\n",
        "plt.xlabel('Edad')\n",
        "plt.ylabel('Ingreso mensual (en miles)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "citDwhID-dqH"
      },
      "outputs": [],
      "source": [
        "#Estandarizar las características numéricas.\n",
        "scaler = StandardScaler()\n",
        "# Change the column name to match the actual column name in your DataFrame\n",
        "df[['Edad', 'Ingreso mensual (miles)']] = scaler.fit_transform(df[['Edad', 'Ingreso mensual (miles)']])\n",
        "# Consejo: Las columnas que pongamos del lado izquierdo deben ser las mismas a las del lado derecho\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0X4qr4F_htb"
      },
      "outputs": [],
      "source": [
        "#Estandarizando:\n",
        "scaler = StandardScaler()\n",
        "# Correcting the column name to \"Ingreso mensual (miles)\"\n",
        "df[[\"Edad\", \"Ingreso mensual (miles)\"]] = scaler.fit_transform(df[[\"Edad\", \"Ingreso mensual (miles)\"]])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d24jnNeAJvPf"
      },
      "source": [
        "#Grficando data despues de estandarización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ECMty_lJ1sM"
      },
      "outputs": [],
      "source": [
        "# Graficar los datos después de la estandarización\n",
        "plt.subplot(1, 2, 2)\n",
        "# Use the correct column name: 'Ingreso mensual (miles)'\n",
        "plt.scatter(df['Edad'], df['Ingreso mensual (miles)'])\n",
        "plt.title('Datos estandarizados')\n",
        "plt.xlabel('Edad')\n",
        "plt.ylabel('Ingreso mensual (en miles)')\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr6MXhIpKN-6"
      },
      "source": [
        "##Escalando Min-MAX (Min-Max Scaling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJc88vxTObjC"
      },
      "outputs": [],
      "source": [
        "#Normalizar de [0,1]\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Crear un DataFrame de ejemplo\n",
        "data = {\n",
        "    'Feature1': [10, 20, 30, 40, 50],\n",
        "    'Feature2': [0.1, 0.5, 0.8, 1.2, 1.5]\n",
        "}\n",
        "\n",
        "# Mostrar el DataFrame con datos sin escalar\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV-EiGZfQHb1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFra7i6qn_du"
      },
      "outputs": [],
      "source": [
        "# Escalar las características al rango [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "df[['Feature1', 'Feature2']] = scaler.fit_transform(df[['Feature1', 'Feature2']])\n",
        "\n",
        "# Mostrar el DataFrame con datos escalados Min-Max\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MHJ27tyQmT6"
      },
      "source": [
        "##Encontrar varianza(qué tanto variían los datos; aportanto más info a nuestro modelo) y correlación(Qué variables utilizar y cuáles no), para así tener data training:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-XJY7NTUmol"
      },
      "source": [
        "##Features de entrenamiento; outliers:\n",
        "##1. released year\n",
        "##2. In spotify playlist\n",
        "##3. Instrumentalness\n",
        "##4. Liveliness\n",
        "###.5. Speachnees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z6_FUmoemM5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Transform data types: string\n",
        "data[\"released_year\"] = data[\"released_year\"].astype(str)\n",
        "data[\"in_spotify_playlists\"] = data[\"in_spotify_playlists\"].astype(str)\n",
        "data[\"instrumentalness\"] = data[\"instrumentalness\"].astype(str)\n",
        "data[\"liveness\"] = data[\"liveness\"].astype(str)\n",
        "data[\"speechiness\"] = data[\"speechiness\"].astype(str)\n",
        "\n",
        "# Assigning features\n",
        "feature1 = data['released_year']\n",
        "feature2 = data['in_spotify_playlists']\n",
        "feature3 = data['instrumentalness']\n",
        "feature4 = data['liveness']\n",
        "feature5 = data['speechiness']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_u6yYwziZW-"
      },
      "outputs": [],
      "source": [
        "#Making our code agnostic, will run through CPU or GPU\n",
        "# Setup device agnostic code: will run either on gpu or cpu\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDMBVQw35b6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalizando Features\n"
      ],
      "metadata": {
        "id": "DFHscsDRiukp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1fMPXHCpQLp"
      },
      "outputs": [],
      "source": [
        "''' import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        " '''\n",
        "# Load your data (ensure you've already preprocessed it as described earlier)\n",
        "''' file_path = '/mnt/data/spotify-2023.csv'\n",
        "data = pd.read_csv(file_path, encoding='latin1') '''\n",
        "\n",
        "# Extract and preprocess features\n",
        "data[\"instrumentalness\"] = data[\"instrumentalness_%\"].astype(float) / 100\n",
        "data[\"liveness\"] = data[\"liveness_%\"].astype(float) / 100\n",
        "data[\"speechiness\"] = data[\"speechiness_%\"].astype(float) / 100\n",
        "\n",
        "# Define input features and target variable\n",
        "features = data[[\"released_year\", \"in_spotify_playlists\", \"instrumentalness\", \"liveness\", \"speechiness\"]].values\n",
        "target = data[\"streams\"].astype(float).values  # Ensure target is numeric\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X = torch.tensor(features, dtype=torch.float32)\n",
        "y = torch.tensor(target, dtype=torch.float32).unsqueeze(1)  # Make y a 2D tensor\n",
        "\n",
        "# Define the model\n",
        "class SpotifyLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Linear layer with 5 input features and 1 output feature\n",
        "        self.linear_layer = nn.Linear(in_features=5, out_features=1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.linear_layer(x)\n",
        "\n",
        "# Initialize the model\n",
        "torch.manual_seed(42)\n",
        "model_0 = SpotifyLinearRegression()\n",
        "\n",
        "# Check the model's parameters\n",
        "print(\"Model's initial state_dict:\")\n",
        "print(model_0.state_dict())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}